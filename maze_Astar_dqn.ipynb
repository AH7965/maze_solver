{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Maze with A-star algorithm, Q-learning and Deep Q-network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective of this notebook is to solve self-made maze with A-star algorithm, Q-learning and Deep Q-network.\n",
    "### The maze is in square shape, consists of start point, goal point and tiles in the mid of them.\n",
    "### Each tile has numericals as its point. In other words, if you step on to the tile with -1, you get 1 point subtracted.\n",
    "### The maze has blocks to prevent you from taking the route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pds\n",
    "import random\n",
    "import copy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from collections import deque\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maze Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Maze(object):\n",
    "    def __init__(self, size=10, blocks_rate=0.1):\n",
    "        self.size = size if size > 3 else 10\n",
    "        self.blocks = int((size ** 2) * blocks_rate) \n",
    "        self.s_list = []\n",
    "        self.maze_list = []\n",
    "        self.e_list = []\n",
    "\n",
    "    def create_mid_lines(self, k):\n",
    "        if k == 0: self.maze_list.append(self.s_list)\n",
    "        elif k == self.size - 1: self.maze_list.append(self.e_list)\n",
    "        else:\n",
    "            tmp_list = []\n",
    "            for l in range(0,self.size):\n",
    "                if l == 0: tmp_list.extend(\"#\")\n",
    "                elif l == self.size-1: tmp_list.extend(\"#\")\n",
    "                else:\n",
    "                    a = random.randint(-1, 0)\n",
    "                    tmp_list.extend([a])\n",
    "            self.maze_list.append(tmp_list)\n",
    "\n",
    "    def insert_blocks(self, k, s_r, e_r):\n",
    "        b_y = random.randint(1, self.size-2)\n",
    "        b_x = random.randint(1, self.size-2)\n",
    "        if [b_y, b_x] == [1, s_r] or [b_y, b_x] == [self.size - 2, e_r]: k = k-1\n",
    "        else: self.maze_list[b_y][b_x] = \"#\"\n",
    "            \n",
    "    def generate_maze(self): \n",
    "        s_r = random.randint(1, (self.size / 2) - 1)\n",
    "        for i in range(0, self.size):\n",
    "            if i == s_r: self.s_list.extend(\"S\")\n",
    "            else: self.s_list.extend(\"#\")\n",
    "        start_point = [0, s_r]\n",
    "\n",
    "        e_r = random.randint((self.size / 2) + 1, self.size - 2)\n",
    "        for j in range(0, self.size):\n",
    "            if j == e_r: self.e_list.extend([50])\n",
    "            else: self.e_list.extend(\"#\")\n",
    "        goal_point = [self.size - 1, e_r]\n",
    "\n",
    "        for k in range(0, self.size):\n",
    "            self.create_mid_lines(k)\n",
    "        \n",
    "        for k in range(self.blocks):\n",
    "            self.insert_blocks(k, s_r, e_r)\n",
    "\n",
    "        return self.maze_list, start_point, goal_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maze functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Field(object):\n",
    "    def __init__(self, maze, start_point, goal_point):\n",
    "        self.maze = maze\n",
    "        self.start_point = start_point\n",
    "        self.goal_point = goal_point\n",
    "        self.movable_vec = [[1,0],[-1,0],[0,1],[0,-1]]\n",
    "\n",
    "    def display(self, point=None):\n",
    "        field_data = copy.deepcopy(self.maze)\n",
    "        if not point is None:\n",
    "                y, x = point\n",
    "                field_data[y][x] = \"@@\"\n",
    "        else:\n",
    "                point = \"\"\n",
    "        for line in field_data:\n",
    "                print (\"\\t\" + \"%3s \" * len(line) % tuple(line))\n",
    "\n",
    "    def get_actions(self, state):\n",
    "        movables = []\n",
    "        if state == self.start_point:\n",
    "            y = state[0] + 1\n",
    "            x = state[1]\n",
    "            a = [[y, x]]\n",
    "            return a\n",
    "        else:\n",
    "            for v in self.movable_vec:\n",
    "                y = state[0] + v[0]\n",
    "                x = state[1] + v[1]\n",
    "                if not(0 < x < len(self.maze) and\n",
    "                       0 <= y <= len(self.maze) - 1 and\n",
    "                       maze[y][x] != \"#\" and\n",
    "                       maze[y][x] != \"S\"):\n",
    "                    continue\n",
    "                movables.append([y,x])\n",
    "            if len(movables) != 0:\n",
    "                return movables\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    def get_val(self, state):\n",
    "        y, x = state\n",
    "        if state == self.start_point: return 0, False\n",
    "        else:\n",
    "            v = float(self.maze[y][x])\n",
    "            if state == self.goal_point: \n",
    "                return v, True\n",
    "            else: \n",
    "                return v, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n"
     ]
    }
   ],
   "source": [
    "size = 10\n",
    "barriar_rate = 0.1\n",
    "\n",
    "maze_1 = Maze(size, barriar_rate)\n",
    "maze, start_point, goal_point = maze_1.generate_maze()\n",
    "maze_field = Field(maze, start_point, goal_point)\n",
    "\n",
    "maze_field.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the maze with A-star algorithm\n",
    "### https://en.wikipedia.org/wiki/A*_search_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Node(object):    \n",
    "    def __init__(self, state, start_point, goal_point):\n",
    "        self.state = state\n",
    "        self.start_point = start_point\n",
    "        self.goal_point = goal_point\n",
    "        self.hs = (self.state[0] - self.goal_point[0]) ** 2 + (self.state[1] - self.goal_point[1]) ** 2\n",
    "        self.fs = 0\n",
    "        self.parent_node = None\n",
    "    \n",
    "    def confirm_goal(self):\n",
    "        if self.goal_point == self.state: return True\n",
    "        else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NodeList(list):\n",
    "    def find_nodelist(self, state):\n",
    "        node_list = [t for t in self if t.state==state]\n",
    "        return node_list[0] if node_list != [] else None\n",
    "    def remove_from_nodelist(self, node):\n",
    "        del self[self.index(node)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Aster_Solver(object):\n",
    "    def __init__(self, maze, start_point, goal_point):\n",
    "        self.Field = maze\n",
    "        self.start_point = start_point\n",
    "        self.goal_point = goal_point\n",
    "        self.open_list = NodeList()\n",
    "        self.close_list = NodeList()\n",
    "        self.steps = 0\n",
    "        self.score = 0\n",
    "        \n",
    "    def set_initial_node(self):\n",
    "        node = Node(self.start_point, self.start_point, self.goal_point)\n",
    "        node.start_point = self.start_point\n",
    "        node.goal_point = self.goal_point \n",
    "        return node\n",
    "                \n",
    "    def go_next(self, next_actions, node):\n",
    "        node_gs = node.fs - node.hs\n",
    "        for action in next_actions:\n",
    "            open_list = self.open_list.find_nodelist(action)\n",
    "            dist = (node.state[0] - action[0]) ** 2 + (node.state[1] - action[1]) ** 2\n",
    "            if open_list:\n",
    "                if open_list.fs > node_gs + open_list.hs + dist:\n",
    "                    open_list.fs = node_gs + open_list.hs + dist\n",
    "                    open_list.parent_node = node\n",
    "            else:\n",
    "                open_list = self.close_list.find_nodelist(action)\n",
    "                if open_list:\n",
    "                    if open_list.fs > node_gs + open_list.hs + dist:\n",
    "                        open_list.fs = node_gs + open_list.hs + dist\n",
    "                        open_list.parent_node = node\n",
    "                        self.open_list.append(open_list)\n",
    "                        self.close_list.remove_from_nodelist(open_list)\n",
    "                else:\n",
    "                    open_list = Node(action, self.start_point, self.goal_point)\n",
    "                    open_list.fs = node_gs + open_list.hs + dist\n",
    "                    open_list.parent_node = node\n",
    "                    self.open_list.append(open_list)\n",
    "    \n",
    "    def solve_maze(self):\n",
    "        node = self.set_initial_node()\n",
    "        node.fs = node.hs\n",
    "        self.open_list.append(node)\n",
    "        \n",
    "        while True:\n",
    "            self.steps += 1\n",
    "            node = min(self.open_list, key = lambda node:node.fs)\n",
    "            print (\"current state:  {0}\".format(node.state))\n",
    "            self.Field.display(node.state)\n",
    "            \n",
    "            reward, tf = self.Field.get_val(node.state)\n",
    "            self.score =  self.score + reward\n",
    "            print(\"current step: {0} \\t score: {1} \\n\".format(self.steps, self.score))\n",
    "            if tf == True: break\n",
    "\n",
    "            self.open_list.remove_from_nodelist(node)\n",
    "            self.close_list.append(node)\n",
    "            \n",
    "            next_actions = self.Field.get_actions(node.state)   \n",
    "            self.go_next(next_actions, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current state:  [0, 4]\n",
      "\t  #   #   #   #  @@   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 1 \t score: 0 \n",
      "\n",
      "current state:  [1, 4]\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  @@   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 2 \t score: -1.0 \n",
      "\n",
      "current state:  [2, 4]\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  @@   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 3 \t score: -2.0 \n",
      "\n",
      "current state:  [3, 4]\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  @@   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 4 \t score: -3.0 \n",
      "\n",
      "current state:  [4, 4]\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0  @@   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 5 \t score: -3.0 \n",
      "\n",
      "current state:  [4, 5]\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0  @@   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 6 \t score: -3.0 \n",
      "\n",
      "current state:  [5, 5]\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  @@  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 7 \t score: -4.0 \n",
      "\n",
      "current state:  [6, 5]\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  @@  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 8 \t score: -5.0 \n",
      "\n",
      "current state:  [7, 5]\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1  @@  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 9 \t score: -5.0 \n",
      "\n",
      "current state:  [8, 5]\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #  @@   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 10 \t score: -5.0 \n",
      "\n",
      "current state:  [8, 6]\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0  @@   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 11 \t score: -5.0 \n",
      "\n",
      "current state:  [9, 6]\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  @@   #   #   # \n",
      "current step: 12 \t score: 45.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "astar_Solver = Aster_Solver(maze_field, start_point, goal_point)\n",
    "astar_Solver.solve_maze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Solving the maze in Q-learning\n",
    "### https://en.wikipedia.org/wiki/Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QLearning_Solver(object):\n",
    "    def __init__(self, maze):\n",
    "        self.Qvalue = {}\n",
    "        self.Field = maze\n",
    "        self.alpha = 0.2\n",
    "        self.gamma  = 0.9\n",
    "        self.epsilon = 0.2\n",
    "        self.steps = 0\n",
    "        self.score = 0\n",
    "\n",
    "    def qlearn(self, greedy_flg=False):\n",
    "        state = self.Field.start_point\n",
    "        while True:\n",
    "            if greedy_flg:\n",
    "                self.steps += 1\n",
    "                action = self.choose_action_greedy(state)\n",
    "                print(\"current state: {0} -> action: {1} \".format(state, action))\n",
    "                self.Field.display(action)\n",
    "                reward, tf = self.Field.get_val(action)\n",
    "                self.score =  self.score + reward\n",
    "                print(\"current step: {0} \\t score: {1}\\n\".format(self.steps, self.score))\n",
    "\n",
    "            else:\n",
    "                action = self.choose_action(state)    \n",
    "            if self.update_Qvalue(state, action):\n",
    "                break\n",
    "            else:\n",
    "                state = action\n",
    "\n",
    "    def update_Qvalue(self, state, action):\n",
    "        Q_s_a = self.get_Qvalue(state, action)\n",
    "        mQ_s_a = max([self.get_Qvalue(action, n_action) for n_action in self.Field.get_actions(action)])\n",
    "        r_s_a, finish_flg = self.Field.get_val(action)\n",
    "        q_value = Q_s_a + self.alpha * ( r_s_a +  self.gamma * mQ_s_a - Q_s_a)\n",
    "        self.set_Qvalue(state, action, q_value)\n",
    "        return finish_flg\n",
    "\n",
    "\n",
    "    def get_Qvalue(self, state, action):\n",
    "        state = (state[0],state[1])\n",
    "        action = (action[0],action[1])\n",
    "        try:\n",
    "            return self.Qvalue[state][action]\n",
    "        except KeyError:\n",
    "            return 0.0\n",
    "\n",
    "    def set_Qvalue(self, state, action, q_value):\n",
    "        state = (state[0],state[1])\n",
    "        action = (action[0],action[1])\n",
    "        self.Qvalue.setdefault(state,{})\n",
    "        self.Qvalue[state][action] = q_value\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if self.epsilon < random.random():\n",
    "            return random.choice(self.Field.get_actions(state))\n",
    "        else:\n",
    "            return self.choose_action_greedy(state)\n",
    "\n",
    "    def choose_action_greedy(self, state):\n",
    "        best_actions = []\n",
    "        max_q_value = -100\n",
    "        for a in self.Field.get_actions(state):\n",
    "            q_value = self.get_Qvalue(state, a)\n",
    "            if q_value > max_q_value:\n",
    "                best_actions = [a,]\n",
    "                max_q_value = q_value\n",
    "            elif q_value == max_q_value:\n",
    "                best_actions.append(a)\n",
    "        return random.choice(best_actions)\n",
    "\n",
    "    def dump_Qvalue(self):\n",
    "        print(\"##### Dump Qvalue #####\")\n",
    "        for i, s in enumerate(self.Qvalue.keys()):\n",
    "            for a in self.Qvalue[s].keys():\n",
    "                print(\"\\t\\tQ(s, a): Q(%s, %s): %s\" % (str(s), str(a), str(self.Qvalue[s][a])))\n",
    "            if i != len(self.Qvalue.keys())-1: \n",
    "                print('\\t----- next state -----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Dump Qvalue #####\n",
      "\t\tQ(s, a): Q((7, 3), (7, 4)): 31.80499999999995\n",
      "\t\tQ(s, a): Q((7, 3), (8, 3)): 23.862049999999947\n",
      "\t\tQ(s, a): Q((7, 3), (7, 2)): 24.862049999999947\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((4, 7), (3, 7)): 20.039254999999947\n",
      "\t\tQ(s, a): Q((4, 7), (5, 7)): 27.08549999999995\n",
      "\t\tQ(s, a): Q((4, 7), (4, 6)): 27.08549999999995\n",
      "\t\tQ(s, a): Q((4, 7), (4, 8)): 23.185844999999944\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((4, 4), (4, 5)): 24.862049999999947\n",
      "\t\tQ(s, a): Q((4, 4), (3, 4)): 19.138260499999944\n",
      "\t\tQ(s, a): Q((4, 4), (4, 3)): 20.138260499999944\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((6, 6), (5, 6)): 30.094999999999953\n",
      "\t\tQ(s, a): Q((6, 6), (7, 6)): 39.499999999999964\n",
      "\t\tQ(s, a): Q((6, 6), (6, 5)): 31.80499999999995\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((5, 6), (5, 7)): 27.08549999999995\n",
      "\t\tQ(s, a): Q((5, 6), (6, 6)): 34.549999999999955\n",
      "\t\tQ(s, a): Q((5, 6), (4, 6)): 27.08549999999995\n",
      "\t\tQ(s, a): Q((5, 6), (5, 5)): 27.624499999999948\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((2, 8), (2, 7)): 18.935329499999945\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((7, 7), (7, 6)): 39.499999999999964\n",
      "\t\tQ(s, a): Q((7, 7), (7, 8)): 31.80499999999995\n",
      "\t\tQ(s, a): Q((7, 7), (8, 7)): 40.499999999999964\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((6, 2), (6, 1)): 19.13825902445052\n",
      "\t\tQ(s, a): Q((6, 2), (5, 2)): 18.238259477290345\n",
      "\t\tQ(s, a): Q((6, 2), (7, 2)): 24.862049999999947\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((1, 6), (1, 5)): 18.124434449999942\n",
      "\t\tQ(s, a): Q((1, 6), (2, 6)): 21.039254999999947\n",
      "\t\tQ(s, a): Q((1, 6), (1, 7)): 16.041796549999944\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((3, 7), (2, 7)): 18.935329499999945\n",
      "\t\tQ(s, a): Q((3, 7), (4, 7)): 23.376949999999947\n",
      "\t\tQ(s, a): Q((3, 7), (3, 6)): 23.376949999999947\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((5, 1), (4, 1)): 15.311788825556171\n",
      "\t\tQ(s, a): Q((5, 1), (6, 1)): 19.13825724009334\n",
      "\t\tQ(s, a): Q((5, 1), (5, 2)): 18.238200734167904\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((2, 5), (1, 5)): 18.124434449999942\n",
      "\t\tQ(s, a): Q((2, 5), (2, 6)): 21.039254999999947\n",
      "\t\tQ(s, a): Q((2, 5), (2, 4)): 17.124434449999942\n",
      "\t\tQ(s, a): Q((2, 5), (3, 5)): 22.375844999999945\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((8, 5), (8, 6)): 44.99999999999997\n",
      "\t\tQ(s, a): Q((8, 5), (7, 5)): 36.44999999999995\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((7, 2), (7, 3)): 27.624499999999948\n",
      "\t\tQ(s, a): Q((7, 2), (6, 2)): 21.37584499990003\n",
      "\t\tQ(s, a): Q((7, 2), (8, 2)): 21.375844999998673\n",
      "\t\tQ(s, a): Q((7, 2), (7, 1)): 22.375844999999927\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((7, 8), (8, 8)): 35.44999999999995\n",
      "\t\tQ(s, a): Q((7, 8), (6, 8)): 28.624499999999948\n",
      "\t\tQ(s, a): Q((7, 8), (7, 7)): 36.44999999999995\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((3, 1), (3, 2)): 16.311990360263056\n",
      "\t\tQ(s, a): Q((3, 1), (4, 1)): 15.311852479355402\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((5, 5), (5, 6)): 30.094999999999953\n",
      "\t\tQ(s, a): Q((5, 5), (4, 5)): 24.862049999999947\n",
      "\t\tQ(s, a): Q((5, 5), (6, 5)): 31.80499999999995\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((8, 1), (8, 2)): 21.375844932793225\n",
      "\t\tQ(s, a): Q((8, 1), (7, 1)): 22.375844995996232\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((7, 6), (8, 6)): 44.99999999999997\n",
      "\t\tQ(s, a): Q((7, 6), (7, 5)): 36.44999999999995\n",
      "\t\tQ(s, a): Q((7, 6), (7, 7)): 36.44999999999995\n",
      "\t\tQ(s, a): Q((7, 6), (6, 6)): 34.549999999999955\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((4, 8), (4, 7)): 23.376949999999947\n",
      "\t\tQ(s, a): Q((4, 8), (5, 8)): 25.762049999999945\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((1, 5), (2, 5)): 20.138260499999944\n",
      "\t\tQ(s, a): Q((1, 5), (1, 6)): 18.935329499999945\n",
      "\t\tQ(s, a): Q((1, 5), (1, 4)): 15.311991004999946\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((3, 3), (3, 2)): 16.311991004999413\n",
      "\t\tQ(s, a): Q((3, 3), (3, 4)): 19.138260499999934\n",
      "\t\tQ(s, a): Q((3, 3), (4, 3)): 20.138260499999944\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((5, 8), (5, 7)): 27.08549999999995\n",
      "\t\tQ(s, a): Q((5, 8), (6, 8)): 28.624499999999948\n",
      "\t\tQ(s, a): Q((5, 8), (4, 8)): 23.185844999999944\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((3, 6), (3, 7)): 20.039254999999947\n",
      "\t\tQ(s, a): Q((3, 6), (2, 6)): 21.039254999999947\n",
      "\t\tQ(s, a): Q((3, 6), (4, 6)): 27.08549999999995\n",
      "\t\tQ(s, a): Q((3, 6), (3, 5)): 22.375844999999945\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((0, 4), (1, 4)): 15.311991004999946\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((1, 3), (1, 4)): 15.311991004999946\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((8, 6), (9, 6)): 49.999999999999986\n",
      "\t\tQ(s, a): Q((8, 6), (7, 6)): 39.499999999999964\n",
      "\t\tQ(s, a): Q((8, 6), (8, 5)): 40.499999999999964\n",
      "\t\tQ(s, a): Q((8, 6), (8, 7)): 40.499999999999964\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((3, 5), (4, 5)): 24.862049999999947\n",
      "\t\tQ(s, a): Q((3, 5), (2, 5)): 20.138260499999944\n",
      "\t\tQ(s, a): Q((3, 5), (3, 4)): 19.138260499999944\n",
      "\t\tQ(s, a): Q((3, 5), (3, 6)): 23.376949999999947\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((4, 1), (4, 2)): 18.12443443567648\n",
      "\t\tQ(s, a): Q((4, 1), (3, 1)): 13.680113657659604\n",
      "\t\tQ(s, a): Q((4, 1), (5, 1)): 17.223183367923976\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((3, 2), (4, 2)): 18.124434449999942\n",
      "\t\tQ(s, a): Q((3, 2), (3, 1)): 13.680787382254426\n",
      "\t\tQ(s, a): Q((3, 2), (3, 3)): 18.124434446660057\n",
      "\t\tQ(s, a): Q((3, 2), (2, 2)): 14.680784417151324\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((2, 6), (2, 7)): 18.935329499999945\n",
      "\t\tQ(s, a): Q((2, 6), (2, 5)): 20.138260499999944\n",
      "\t\tQ(s, a): Q((2, 6), (1, 6)): 18.935329499999945\n",
      "\t\tQ(s, a): Q((2, 6), (3, 6)): 23.376949999999947\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((8, 2), (8, 1)): 20.13826027118035\n",
      "\t\tQ(s, a): Q((8, 2), (8, 3)): 23.86204999936145\n",
      "\t\tQ(s, a): Q((8, 2), (7, 2)): 24.862049999999947\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((7, 1), (8, 1)): 20.13826038863943\n",
      "\t\tQ(s, a): Q((7, 1), (6, 1)): 19.13826017417589\n",
      "\t\tQ(s, a): Q((7, 1), (7, 2)): 24.862049999999947\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((4, 5), (4, 4)): 22.375844999999945\n",
      "\t\tQ(s, a): Q((4, 5), (5, 5)): 27.624499999999948\n",
      "\t\tQ(s, a): Q((4, 5), (3, 5)): 22.375844999999945\n",
      "\t\tQ(s, a): Q((4, 5), (4, 6)): 27.08549999999995\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((2, 2), (3, 2)): 16.311990596045558\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((1, 4), (1, 5)): 18.124434449999942\n",
      "\t\tQ(s, a): Q((1, 4), (1, 3)): 12.780791904499948\n",
      "\t\tQ(s, a): Q((1, 4), (2, 4)): 17.124434449999942\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((7, 5), (7, 4)): 31.80499999999995\n",
      "\t\tQ(s, a): Q((7, 5), (7, 6)): 39.499999999999964\n",
      "\t\tQ(s, a): Q((7, 5), (8, 5)): 40.499999999999964\n",
      "\t\tQ(s, a): Q((7, 5), (6, 5)): 31.80499999999995\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((8, 7), (8, 6)): 44.99999999999997\n",
      "\t\tQ(s, a): Q((8, 7), (8, 8)): 35.44999999999995\n",
      "\t\tQ(s, a): Q((8, 7), (7, 7)): 36.44999999999995\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((6, 8), (7, 8)): 31.80499999999995\n",
      "\t\tQ(s, a): Q((6, 8), (5, 8)): 25.762049999999945\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((4, 2), (4, 1)): 15.311990508862394\n",
      "\t\tQ(s, a): Q((4, 2), (3, 2)): 16.311991004850686\n",
      "\t\tQ(s, a): Q((4, 2), (5, 2)): 18.238260494388257\n",
      "\t\tQ(s, a): Q((4, 2), (4, 3)): 20.138260499999944\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((6, 5), (7, 5)): 36.44999999999995\n",
      "\t\tQ(s, a): Q((6, 5), (5, 5)): 27.624499999999948\n",
      "\t\tQ(s, a): Q((6, 5), (6, 6)): 34.549999999999955\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((5, 3), (5, 2)): 18.23826046656059\n",
      "\t\tQ(s, a): Q((5, 3), (4, 3)): 20.138260499999944\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((2, 7), (3, 7)): 20.039254999999947\n",
      "\t\tQ(s, a): Q((2, 7), (2, 6)): 21.039254999999947\n",
      "\t\tQ(s, a): Q((2, 7), (1, 7)): 16.041796549999944\n",
      "\t\tQ(s, a): Q((2, 7), (2, 8)): 16.041796549999944\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((8, 3), (7, 3)): 27.624499999999948\n",
      "\t\tQ(s, a): Q((8, 3), (8, 2)): 21.37584499999706\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((4, 6), (5, 6)): 30.094999999999953\n",
      "\t\tQ(s, a): Q((4, 6), (4, 5)): 24.862049999999947\n",
      "\t\tQ(s, a): Q((4, 6), (4, 7)): 23.376949999999947\n",
      "\t\tQ(s, a): Q((4, 6), (3, 6)): 23.376949999999947\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((3, 4), (3, 3)): 18.124434449999942\n",
      "\t\tQ(s, a): Q((3, 4), (4, 4)): 22.375844999999945\n",
      "\t\tQ(s, a): Q((3, 4), (2, 4)): 17.124434449999942\n",
      "\t\tQ(s, a): Q((3, 4), (3, 5)): 22.375844999999945\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((6, 1), (5, 1)): 17.22424224563992\n",
      "\t\tQ(s, a): Q((6, 1), (6, 2)): 21.375843741807525\n",
      "\t\tQ(s, a): Q((6, 1), (7, 1)): 22.37584499763386\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((5, 7), (5, 6)): 30.094999999999953\n",
      "\t\tQ(s, a): Q((5, 7), (4, 7)): 23.376949999999947\n",
      "\t\tQ(s, a): Q((5, 7), (5, 8)): 25.762049999999945\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((7, 4), (7, 3)): 27.624499999999948\n",
      "\t\tQ(s, a): Q((7, 4), (7, 5)): 36.44999999999995\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((8, 8), (7, 8)): 31.80499999999995\n",
      "\t\tQ(s, a): Q((8, 8), (8, 7)): 40.499999999999964\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((4, 3), (4, 2)): 18.124434449999942\n",
      "\t\tQ(s, a): Q((4, 3), (4, 4)): 22.375844999999945\n",
      "\t\tQ(s, a): Q((4, 3), (3, 3)): 18.124434449999942\n",
      "\t\tQ(s, a): Q((4, 3), (5, 3)): 17.124434449999942\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((1, 7), (2, 7)): 18.935329499999945\n",
      "\t\tQ(s, a): Q((1, 7), (1, 6)): 18.935329499999945\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((5, 2), (4, 2)): 18.12443441299027\n",
      "\t\tQ(s, a): Q((5, 2), (5, 3)): 17.124432560447335\n",
      "\t\tQ(s, a): Q((5, 2), (6, 2)): 21.37584499986708\n",
      "\t\tQ(s, a): Q((5, 2), (5, 1)): 17.223757910121712\n",
      "\t----- next state -----\n",
      "\t\tQ(s, a): Q((2, 4), (2, 5)): 20.138260499999944\n",
      "\t\tQ(s, a): Q((2, 4), (3, 4)): 19.138260499999944\n",
      "\t\tQ(s, a): Q((2, 4), (1, 4)): 15.311991004999946\n"
     ]
    }
   ],
   "source": [
    "learning_count = 1000\n",
    "QL_solver = QLearning_Solver(maze_field)\n",
    "for i in range(learning_count):\n",
    "    QL_solver.qlearn()\n",
    "\n",
    "QL_solver.dump_Qvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current state: [0, 4] -> action: [1, 4] \n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  @@   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 1 \t score: -1.0\n",
      "\n",
      "current state: [1, 4] -> action: [1, 5] \n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1  @@   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 2 \t score: -1.0\n",
      "\n",
      "current state: [1, 5] -> action: [2, 5] \n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1  @@   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 3 \t score: -1.0\n",
      "\n",
      "current state: [2, 5] -> action: [3, 5] \n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1  @@  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 4 \t score: -1.0\n",
      "\n",
      "current state: [3, 5] -> action: [4, 5] \n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0  @@   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 5 \t score: -1.0\n",
      "\n",
      "current state: [4, 5] -> action: [5, 5] \n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  @@  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 6 \t score: -2.0\n",
      "\n",
      "current state: [5, 5] -> action: [6, 5] \n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  @@  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 7 \t score: -3.0\n",
      "\n",
      "current state: [6, 5] -> action: [7, 5] \n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1  @@  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 8 \t score: -3.0\n",
      "\n",
      "current state: [7, 5] -> action: [8, 5] \n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #  @@   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 9 \t score: -3.0\n",
      "\n",
      "current state: [8, 5] -> action: [8, 6] \n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0  @@   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current step: 10 \t score: -3.0\n",
      "\n",
      "current state: [8, 6] -> action: [9, 6] \n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  @@   #   #   # \n",
      "current step: 11 \t score: 47.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "QL_solver.qlearn(greedy_flg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Solving the maze in Deep Q-learning\n",
    "### https://deepmind.com/research/dqn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN_Solver:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.gamma = 0.9\n",
    "        self.epsilon = 1.0\n",
    "        self.e_decay = 0.9999\n",
    "        self.e_min = 0.01\n",
    "        self.learning_rate = 0.0001\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_shape=(2,2), activation='tanh'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='tanh'))\n",
    "        model.add(Dense(128, activation='tanh'))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        model.compile(loss=\"mse\", optimizer=RMSprop(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember_memory(self, state, action, reward, next_state, next_movables, done):\n",
    "        self.memory.append((state, action, reward, next_state, next_movables, done))\n",
    "\n",
    "    def choose_action(self, state, movables):\n",
    "        if self.epsilon >= random.random():\n",
    "            return random.choice(movables)\n",
    "        else:\n",
    "            return self.choose_best_action(state, movables)\n",
    "        \n",
    "    def choose_best_action(self, state, movables):\n",
    "        best_actions = []\n",
    "        max_act_value = -100\n",
    "        for a in movables:\n",
    "            np_action = np.array([[state, a]])\n",
    "            act_value = self.model.predict(np_action)\n",
    "            if act_value > max_act_value:\n",
    "                best_actions = [a,]\n",
    "                max_act_value = act_value\n",
    "            elif act_value == max_act_value:\n",
    "                best_actions.append(a)\n",
    "        return random.choice(best_actions)\n",
    "\n",
    "    def replay_experience(self, batch_size):\n",
    "        batch_size = min(batch_size, len(self.memory))\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        X = []\n",
    "        Y = []\n",
    "        for i in range(batch_size):\n",
    "            state, action, reward, next_state, next_movables, done = minibatch[i]\n",
    "            input_action = [state, action]\n",
    "            if done:\n",
    "                target_f = reward\n",
    "            else:\n",
    "                next_rewards = []\n",
    "                for i in next_movables:\n",
    "                    np_next_s_a = np.array([[next_state, i]])\n",
    "                    next_rewards.append(self.model.predict(np_next_s_a))\n",
    "                np_n_r_max = np.amax(np.array(next_rewards))\n",
    "                target_f = reward + self.gamma * np_n_r_max\n",
    "            X.append(input_action)\n",
    "            Y.append(target_f)\n",
    "        np_X = np.array(X)\n",
    "        np_Y = np.array([Y]).T\n",
    "        self.model.fit(np_X, np_Y, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.e_min:\n",
    "            self.epsilon *= self.e_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/10000, score: -31.0, e: 1.0 \t @ 202\n",
      "episode: 100/10000, score: 30.0, e: 0.99 \t @ 44\n",
      "episode: 200/10000, score: -3.0, e: 0.98 \t @ 110\n",
      "episode: 300/10000, score: -34.0, e: 0.97 \t @ 188\n",
      "episode: 400/10000, score: -117.0, e: 0.96 \t @ 348\n",
      "episode: 500/10000, score: -59.0, e: 0.95 \t @ 222\n",
      "episode: 600/10000, score: 9.0, e: 0.94 \t @ 108\n",
      "episode: 700/10000, score: -55.0, e: 0.93 \t @ 204\n",
      "episode: 800/10000, score: 39.0, e: 0.92 \t @ 30\n",
      "episode: 900/10000, score: 35.0, e: 0.91 \t @ 28\n",
      "episode: 1000/10000, score: 32.0, e: 0.9 \t @ 34\n",
      "episode: 1100/10000, score: -15.0, e: 0.9 \t @ 164\n",
      "episode: 1200/10000, score: 38.0, e: 0.89 \t @ 30\n",
      "episode: 1300/10000, score: 15.0, e: 0.88 \t @ 70\n",
      "episode: 1400/10000, score: 16.0, e: 0.87 \t @ 86\n",
      "episode: 1500/10000, score: 34.0, e: 0.86 \t @ 26\n",
      "episode: 1600/10000, score: -25.0, e: 0.85 \t @ 154\n",
      "episode: 1700/10000, score: 23.0, e: 0.84 \t @ 54\n",
      "episode: 1800/10000, score: 0.0, e: 0.84 \t @ 104\n",
      "episode: 1900/10000, score: 33.0, e: 0.83 \t @ 38\n",
      "episode: 2000/10000, score: -20.0, e: 0.82 \t @ 166\n",
      "episode: 2100/10000, score: -2.0, e: 0.81 \t @ 96\n",
      "episode: 2200/10000, score: 30.0, e: 0.8 \t @ 44\n",
      "episode: 2300/10000, score: 37.0, e: 0.79 \t @ 28\n",
      "episode: 2400/10000, score: 29.0, e: 0.79 \t @ 38\n",
      "episode: 2500/10000, score: 28.0, e: 0.78 \t @ 46\n",
      "episode: 2600/10000, score: 4.0, e: 0.77 \t @ 116\n",
      "episode: 2700/10000, score: -35.0, e: 0.76 \t @ 194\n",
      "episode: 2800/10000, score: 38.0, e: 0.76 \t @ 26\n",
      "episode: 2900/10000, score: 36.0, e: 0.75 \t @ 36\n",
      "episode: 3000/10000, score: 6.0, e: 0.74 \t @ 86\n",
      "episode: 3100/10000, score: 37.0, e: 0.73 \t @ 28\n",
      "episode: 3200/10000, score: 19.0, e: 0.73 \t @ 68\n",
      "episode: 3300/10000, score: 37.0, e: 0.72 \t @ 40\n",
      "episode: 3400/10000, score: 36.0, e: 0.71 \t @ 22\n",
      "episode: 3500/10000, score: 39.0, e: 0.7 \t @ 28\n",
      "episode: 3600/10000, score: -16.0, e: 0.7 \t @ 128\n",
      "episode: 3700/10000, score: 35.0, e: 0.69 \t @ 30\n",
      "episode: 3800/10000, score: 40.0, e: 0.68 \t @ 30\n",
      "episode: 3900/10000, score: 43.0, e: 0.68 \t @ 18\n",
      "episode: 4000/10000, score: 40.0, e: 0.67 \t @ 16\n",
      "episode: 4100/10000, score: 36.0, e: 0.66 \t @ 38\n",
      "episode: 4200/10000, score: 35.0, e: 0.66 \t @ 26\n",
      "episode: 4300/10000, score: 18.0, e: 0.65 \t @ 74\n",
      "episode: 4400/10000, score: 14.0, e: 0.64 \t @ 64\n",
      "episode: 4500/10000, score: 6.0, e: 0.64 \t @ 66\n",
      "episode: 4600/10000, score: 42.0, e: 0.63 \t @ 16\n",
      "episode: 4700/10000, score: 42.0, e: 0.62 \t @ 18\n",
      "episode: 4800/10000, score: 33.0, e: 0.62 \t @ 32\n",
      "episode: 4900/10000, score: 41.0, e: 0.61 \t @ 26\n",
      "episode: 5000/10000, score: 45.0, e: 0.61 \t @ 10\n",
      "episode: 5100/10000, score: 40.0, e: 0.6 \t @ 20\n",
      "episode: 5200/10000, score: 38.0, e: 0.59 \t @ 30\n",
      "episode: 5300/10000, score: 44.0, e: 0.59 \t @ 12\n",
      "episode: 5400/10000, score: 41.0, e: 0.58 \t @ 20\n",
      "episode: 5500/10000, score: 42.0, e: 0.58 \t @ 14\n",
      "episode: 5600/10000, score: 36.0, e: 0.57 \t @ 26\n",
      "episode: 5700/10000, score: 39.0, e: 0.57 \t @ 24\n",
      "episode: 5800/10000, score: 40.0, e: 0.56 \t @ 24\n",
      "episode: 5900/10000, score: 41.0, e: 0.55 \t @ 16\n",
      "episode: 6000/10000, score: 38.0, e: 0.55 \t @ 26\n",
      "episode: 6100/10000, score: 43.0, e: 0.54 \t @ 12\n",
      "episode: 6200/10000, score: 43.0, e: 0.54 \t @ 18\n",
      "episode: 6300/10000, score: 45.0, e: 0.53 \t @ 16\n",
      "episode: 6400/10000, score: 46.0, e: 0.53 \t @ 10\n",
      "episode: 6500/10000, score: 43.0, e: 0.52 \t @ 26\n",
      "episode: 6600/10000, score: 34.0, e: 0.52 \t @ 28\n",
      "episode: 6700/10000, score: 31.0, e: 0.51 \t @ 38\n",
      "episode: 6800/10000, score: 36.0, e: 0.51 \t @ 26\n",
      "episode: 6900/10000, score: 43.0, e: 0.5 \t @ 22\n",
      "episode: 7000/10000, score: 43.0, e: 0.5 \t @ 12\n",
      "episode: 7100/10000, score: 45.0, e: 0.49 \t @ 12\n",
      "episode: 7200/10000, score: 40.0, e: 0.49 \t @ 26\n",
      "episode: 7300/10000, score: 43.0, e: 0.48 \t @ 22\n",
      "episode: 7400/10000, score: 43.0, e: 0.48 \t @ 20\n",
      "episode: 7500/10000, score: 45.0, e: 0.47 \t @ 12\n",
      "episode: 7600/10000, score: 44.0, e: 0.47 \t @ 16\n",
      "episode: 7700/10000, score: 41.0, e: 0.46 \t @ 20\n",
      "episode: 7800/10000, score: 42.0, e: 0.46 \t @ 18\n",
      "episode: 7900/10000, score: 43.0, e: 0.45 \t @ 20\n",
      "episode: 8000/10000, score: 45.0, e: 0.45 \t @ 16\n",
      "episode: 8100/10000, score: 42.0, e: 0.44 \t @ 20\n",
      "episode: 8200/10000, score: 45.0, e: 0.44 \t @ 12\n",
      "episode: 8300/10000, score: 44.0, e: 0.44 \t @ 12\n",
      "episode: 8400/10000, score: 46.0, e: 0.43 \t @ 12\n",
      "episode: 8500/10000, score: 41.0, e: 0.43 \t @ 16\n",
      "episode: 8600/10000, score: 46.0, e: 0.42 \t @ 14\n",
      "episode: 8700/10000, score: 39.0, e: 0.42 \t @ 22\n",
      "episode: 8800/10000, score: 40.0, e: 0.41 \t @ 20\n",
      "episode: 8900/10000, score: 44.0, e: 0.41 \t @ 12\n",
      "episode: 9000/10000, score: 46.0, e: 0.41 \t @ 12\n",
      "episode: 9100/10000, score: 43.0, e: 0.4 \t @ 18\n",
      "episode: 9200/10000, score: 43.0, e: 0.4 \t @ 20\n",
      "episode: 9300/10000, score: 44.0, e: 0.39 \t @ 14\n",
      "episode: 9400/10000, score: 45.0, e: 0.39 \t @ 14\n",
      "episode: 9500/10000, score: 44.0, e: 0.39 \t @ 18\n",
      "episode: 9600/10000, score: 44.0, e: 0.38 \t @ 16\n",
      "episode: 9700/10000, score: 46.0, e: 0.38 \t @ 14\n",
      "episode: 9800/10000, score: 45.0, e: 0.38 \t @ 22\n",
      "episode: 9900/10000, score: 45.0, e: 0.37 \t @ 16\n"
     ]
    }
   ],
   "source": [
    "state_size = 2\n",
    "action_size = 2\n",
    "dql_solver = DQN_Solver(state_size, action_size)\n",
    "\n",
    "episodes = 10000\n",
    "times = 1000\n",
    "\n",
    "for e in range(episodes):\n",
    "    state = start_point\n",
    "    score = 0\n",
    "    for time in range(times):\n",
    "        movables = maze_field.get_actions(state)\n",
    "        action = dql_solver.choose_action(state, movables)\n",
    "        reward, done = maze_field.get_val(action)\n",
    "        score = score + reward\n",
    "        next_state = action\n",
    "        next_movables = maze_field.get_actions(next_state)\n",
    "        dql_solver.remember_memory(state, action, reward, next_state, next_movables, done)\n",
    "        if done or time == (times - 1):\n",
    "            if e % 100 == 0:\n",
    "                print(\"episode: {}/{}, score: {}, e: {:.2} \\t @ {}\"\n",
    "                        .format(e, episodes, score, dql_solver.epsilon, time))\n",
    "            break\n",
    "        state = next_state\n",
    "    dql_solver.replay_experience(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  #   #   #   #  @@   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current state: [1, 4] -> action: [1, 4] \n",
      "current step: 1 \t score: -1.0\n",
      "\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  @@   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current state: [1, 5] -> action: [1, 5] \n",
      "current step: 2 \t score: -1.0\n",
      "\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1  @@   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current state: [2, 5] -> action: [2, 5] \n",
      "current step: 3 \t score: -1.0\n",
      "\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1  @@   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current state: [3, 5] -> action: [3, 5] \n",
      "current step: 4 \t score: -1.0\n",
      "\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1  @@  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current state: [4, 5] -> action: [4, 5] \n",
      "current step: 5 \t score: -1.0\n",
      "\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0  @@   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current state: [5, 5] -> action: [5, 5] \n",
      "current step: 6 \t score: -2.0\n",
      "\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  @@  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current state: [6, 5] -> action: [6, 5] \n",
      "current step: 7 \t score: -3.0\n",
      "\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  @@  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current state: [7, 5] -> action: [7, 5] \n",
      "current step: 8 \t score: -3.0\n",
      "\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1  @@  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current state: [8, 5] -> action: [8, 5] \n",
      "current step: 9 \t score: -3.0\n",
      "\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #  @@   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current state: [8, 6] -> action: [8, 6] \n",
      "current step: 10 \t score: -3.0\n",
      "\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0  @@   0  -1   # \n",
      "\t  #   #   #   #   #   #  50   #   #   # \n",
      "current state: [9, 6] -> action: [9, 6] \n",
      "current step: 11 \t score: 47.0\n",
      "\n",
      "\t  #   #   #   #   S   #   #   #   #   # \n",
      "\t  #   0   #  -1  -1   0   0  -1   #   # \n",
      "\t  #   #   0   #  -1   0   0   0  -1   # \n",
      "\t  #  -1   0   0  -1   0  -1  -1   #   # \n",
      "\t  #  -1   0   0   0   0   0  -1   0   # \n",
      "\t  #   0  -1  -1   #  -1  -1   0   0   # \n",
      "\t  #  -1  -1   #   #  -1  -1   #   0   # \n",
      "\t  #   0   0  -1  -1   0  -1   0  -1   # \n",
      "\t  #   0  -1  -1   #   0   0   0  -1   # \n",
      "\t  #   #   #   #   #   #  @@   #   #   # \n",
      "goal!\n"
     ]
    }
   ],
   "source": [
    "state = start_point\n",
    "score = 0\n",
    "steps = 0\n",
    "while True:\n",
    "    maze_field.display(state)\n",
    "    steps += 1\n",
    "    movables = maze_field.get_actions(state)\n",
    "    action = dql_solver.choose_best_action(state, movables)\n",
    "    reward, done = maze_field.get_val(action)\n",
    "    score = score + reward\n",
    "    state = action\n",
    "    print(\"current state: {0} -> action: {1} \".format(state, action))\n",
    "    print(\"current step: {0} \\t score: {1}\\n\".format(steps, score))\n",
    "    if done:\n",
    "        maze_field.display(action)\n",
    "        print(\"goal!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
